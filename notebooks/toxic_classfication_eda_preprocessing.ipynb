{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce68c5b",
   "metadata": {},
   "source": [
    "Toxic Comment Classification - Multi Label - NLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697245f3",
   "metadata": {},
   "source": [
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d32523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fbec72",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbba1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the data directory\n",
    "DATA_DIR = Path(\"data/raw\")\n",
    "\n",
    "# Read train and test datasets\n",
    "train_df = pd.read_csv(DATA_DIR /\"train.csv\")\n",
    "test_df = pd.read_csv(DATA_DIR / \"test.csv\")\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ac044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset stats\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ff9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset info\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201830e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5977a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b6a9e",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca582a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df.iloc[:, 2:].sum() # take only label columns\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowsums = train_df.iloc[:, 2:].sum(axis=1) # take label columns and sum it column wise\n",
    "rowsums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_count = 0\n",
    "\n",
    "for i, count in rowsums.items():\n",
    "    if count==0:\n",
    "        no_label_count += 1\n",
    "        \n",
    "print('Total number of comments:', len(train_df))\n",
    "print('Total number of comments without labels:', no_label_count)\n",
    "print('Total labels:', x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(x=x.index, y=x.values, alpha=0.8, palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:brown', 'tab:red', 'tab:grey'])\n",
    "plt.title('Label Counts')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.countplot(x=rowsums.values, alpha=0.8, palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:brown', 'tab:red', 'tab:grey'])\n",
    "plt.title('Labels per Comment')\n",
    "plt.ylabel('# of Occurences')\n",
    "plt.xlabel('# of Labels')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27aef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=train_df.iloc[:,2:-1]\n",
    "# filter temp by removing clean comments\n",
    "# temp_df=temp_df[~train.clean]\n",
    "\n",
    "corr=temp_df.corr()\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr,\n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03da8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_col=\"toxic\"\n",
    "corr_mats=[]\n",
    "for other_col in temp_df.columns[1:]:\n",
    "    confusion_matrix = pd.crosstab(temp_df[main_col], temp_df[other_col])\n",
    "    corr_mats.append(confusion_matrix)\n",
    "out = pd.concat(corr_mats,axis=1,keys=temp_df.columns[1:])\n",
    "\n",
    "#cell highlighting\n",
    "# out = out.style.apply(highlight_min,axis=0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58d6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30ebbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "subset_toxic=train_df[train_df.toxic==True]\n",
    "text=subset_toxic.comment_text.values\n",
    "wc= WordCloud(background_color=\"black\",max_words=2000,stopwords=stopwords)\n",
    "wc.generate(\" \".join(text))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\n",
    "plt.savefig('insights/wordclouds/toxic_comments_wc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013900d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_severe_toxic=train_df[train_df.severe_toxic==True]\n",
    "text=subset_severe_toxic.comment_text.values\n",
    "wc= WordCloud(background_color=\"black\",max_words=2000,stopwords=stopwords)\n",
    "wc.generate(\" \".join(text))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\n",
    "plt.savefig('insights/wordclouds/severe_toxic_comments_wc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e82a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_threat=train_df[train_df.threat==True]\n",
    "text=subset_threat.comment_text.values\n",
    "wc= WordCloud(background_color=\"black\",max_words=2000,stopwords=stopwords)\n",
    "wc.generate(\" \".join(text))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\n",
    "plt.savefig('insights/wordclouds/threat_comments_wc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756562e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_insult=train_df[train_df.insult==True]\n",
    "text=subset_insult.comment_text.values\n",
    "wc= WordCloud(background_color=\"black\",max_words=2000,stopwords=stopwords)\n",
    "wc.generate(\" \".join(text))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wc.recolor(colormap= 'viridis' , random_state=17), alpha=0.98)\n",
    "plt.savefig('insights/wordclouds/insult_comments_wc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51affa87",
   "metadata": {},
   "source": [
    "Are longer comments more toxic ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c159ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "if 'is_clean' not in train_df.columns:\n",
    "    train_df['is_clean'] = (train_df[label_col].sum(axis=1) == 0).astype(int)\n",
    "\n",
    "# Total characters\n",
    "train_df['total_len'] = train_df['comment_text'].apply(len)\n",
    "test_df['total_len'] = test_df['comment_text'].apply(len)\n",
    "\n",
    "# Sentence count\n",
    "train_df['sent_count'] = train_df[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\", str(x))) + 1)\n",
    "test_df['sent_count'] = test_df[\"comment_text\"].apply(lambda x: len(re.findall(\"\\n\", str(x))) + 1)\n",
    "\n",
    "# Word count\n",
    "train_df['word_count'] = train_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "test_df['word_count'] = test_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Plot KDEs\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.suptitle(\"Are longer comments more toxic?\", fontsize=18)\n",
    "\n",
    "# Characters\n",
    "plt.subplot(131)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['total_len'], label=\"UnClean\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['total_len'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.xlabel('# of Chars', fontsize=12)\n",
    "\n",
    "# Words\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['word_count'], label=\"UnClean\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['word_count'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.xlabel('# of Words', fontsize=12)\n",
    "\n",
    "# Sentences\n",
    "plt.subplot(133)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['sent_count'], label=\"UnClean\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['sent_count'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.xlabel('# of Sentences', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5dedf",
   "metadata": {},
   "source": [
    "most comments are having less than 25 sentences & less than 250 words\n",
    "\n",
    "unclean comments are having more no.of words in less no.of sentences.\n",
    "\n",
    "The distrubution plots of clean & unclean of all three plots are very much overlapping with each others, indicating these features are going to be less significant in differentiating them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Ensure is_clean exists (0 = toxic, 1 = clean)\n",
    "label_col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "if 'is_clean' not in train_df.columns:\n",
    "    train_df['is_clean'] = (train_df[label_col].sum(axis=1) == 0).astype(int)\n",
    "\n",
    "# Capital letters count\n",
    "train_df['capitals'] = train_df['comment_text'].apply(lambda x: sum(1 for c in str(x) if c.isupper()))\n",
    "test_df['capitals'] = test_df['comment_text'].apply(lambda x: sum(1 for c in str(x) if c.isupper()))\n",
    "\n",
    "# Punctuation count\n",
    "train_df['punct_count'] = train_df['comment_text'].apply(lambda x: sum(1 for c in str(x) if c in string.punctuation))\n",
    "test_df['punct_count'] = test_df['comment_text'].apply(lambda x: sum(1 for c in str(x) if c in string.punctuation))\n",
    "\n",
    "# Smilies count\n",
    "smilies = (':-)', ':)', ';-)', ';)')\n",
    "train_df['smilies_count'] = train_df['comment_text'].apply(lambda comment: sum(str(comment).count(s) for s in smilies))\n",
    "test_df['smilies_count'] = test_df['comment_text'].apply(lambda comment: sum(str(comment).count(s) for s in smilies))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.suptitle(\"Does the Presence of Special Characters Vary with Toxicity?\", fontsize=18)\n",
    "\n",
    "# Capitals\n",
    "plt.subplot(131)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['capitals'], label=\"Toxic\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['capitals'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.xlabel('# of Capital Letters', fontsize=12)\n",
    "\n",
    "# Punctuations\n",
    "plt.subplot(132)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['punct_count'], label=\"Toxic\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['punct_count'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.xlabel('# of Punctuations', fontsize=12)\n",
    "\n",
    "# Smilies\n",
    "plt.subplot(133)\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['smilies_count'], label=\"Toxic\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['smilies_count'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.xlabel('# of Smilies', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dabb1d3",
   "metadata": {},
   "source": [
    "presence of captial letters is more in case of unclean comments, but the distrbutions are overlapping making it a difficult feature for models to extract information.\n",
    "\n",
    "most of the clean comments are having punctuations less than 100 while for unclean comments it spread to max of 5000 punctuations.\n",
    "\n",
    "no.of smilies in unclean v/s clean comments is very much similar and unclean comments are having more comments with no.of smilies = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670aaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique word count\n",
    "train_df['unique_word_count'] = train_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df['unique_word_count'] = test_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# Unique ratio\n",
    "train_df['unique_word_percent'] = (train_df['unique_word_count'] / train_df['word_count']) * 100\n",
    "test_df['unique_word_percent'] = (test_df['unique_word_count'] / test_df['word_count']) * 100\n",
    "\n",
    "# ---------- Plotting ------------\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.suptitle(\"Comments with Less-Unique-Words (Spam) vs Toxicity?\", fontsize=18)\n",
    "\n",
    "# KDE plot for unique word percentage\n",
    "plt.subplot(121)\n",
    "plt.title(\"% of Unique Words in Comments\")\n",
    "sns.kdeplot(train_df[train_df.is_clean == 0]['unique_word_percent'], label=\"Toxic\", shade=True, color='r')\n",
    "sns.kdeplot(train_df[train_df.is_clean == 1]['unique_word_percent'], label=\"Clean\")\n",
    "plt.legend()\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.xlabel('Percent Unique Words', fontsize=12)\n",
    "\n",
    "# Violin plot for comments with <25% unique words\n",
    "plt.subplot(122)\n",
    "sns.violinplot(\n",
    "    y='unique_word_count', x='is_clean',\n",
    "    data=train_df[train_df['unique_word_percent'] < 25],\n",
    "    split=True, inner=\"quart\"\n",
    ")\n",
    "plt.xlabel('is_Clean', fontsize=12)\n",
    "plt.ylabel('# of Unique Words', fontsize=12)\n",
    "plt.title(\"# Unique Words vs Toxicity\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3cd9fb",
   "metadata": {},
   "source": [
    "There is a wide spread area for unclean points in the unique word percentage range of 1-10%, Interesting there are clean comments as well with lesser number of unique words.\n",
    "\n",
    "This feature seems carry some significance especially incase of sentences with less unique words.\n",
    "\n",
    "lets once see how text in clean-spam & unclean-spam comments look like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092a02c8",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f8e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(f\"Number of stopwords: {len(stop_words)}\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "CONTRACTIONS = {\n",
    "    \"can't\": \"cannot\", \"won't\": \"will not\", \"i'm\": \"i am\", \"it's\": \"it is\",\n",
    "    \"don't\": \"do not\", \"didn't\": \"did not\", \"you're\": \"you are\",\n",
    "    \"they're\": \"they are\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
    "    # add more as needed\n",
    "}\n",
    "def expand_contractions(text):\n",
    "    def replace(match):\n",
    "        return CONTRACTIONS.get(match.group(0).lower(), match.group(0))\n",
    "    pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, CONTRACTIONS.keys())) + r')\\b', flags=re.IGNORECASE)\n",
    "    return pattern.sub(replace, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.lower()\n",
    "    text = expand_contractions(text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' ', text)              # remove urls\n",
    "    text = re.sub(r'\\d+', ' ', text)                           # remove numbers (optional)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()                   # normalize spaces\n",
    "    # remove stopwords\n",
    "    tokens = [t for t in text.split() if t not in eng_stopwords]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e445490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "train_df['comment_text_clean'] = train_df['comment_text'].progress_apply(clean_text)\n",
    "test_df['comment_text_clean'] = test_df['comment_text'].progress_apply(clean_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
